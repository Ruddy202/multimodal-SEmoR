{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"TRIAL_WITH_BERTCombined_ses5_test.ipynb","provenance":[]},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2l1uRMphIfXl","executionInfo":{"status":"ok","timestamp":1613626108273,"user_tz":-480,"elapsed":108212,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"2fd8e74f-7cd3-44cc-8376-ce0dfa70c553"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ARfxCHMaI1a0","executionInfo":{"status":"ok","timestamp":1613626160358,"user_tz":-480,"elapsed":48367,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"bc82b578-f14a-425c-e786-2b9aafb786c4"},"source":["!pip install bert-for-tf2\r\n","!pip install sentencepiece\r\n","!pip install --upgrade ktrain"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting bert-for-tf2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/a1/acb891630749c56901e770a34d6bac8a509a367dd74a05daf7306952e910/bert-for-tf2-0.14.9.tar.gz (41kB)\n","\r\u001b[K     |████████                        | 10kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.6MB/s \n","\u001b[?25hCollecting py-params>=0.9.6\n","  Downloading https://files.pythonhosted.org/packages/aa/e0/4f663d8abf83c8084b75b995bd2ab3a9512ebc5b97206fde38cef906ab07/py-params-0.10.2.tar.gz\n","Collecting params-flow>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n","Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n","  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-cp36-none-any.whl size=30534 sha256=7dd2f145cc5d0ac3c37379bd8dda254be19c709d24e33d394404e3d31b6d778b\n","  Stored in directory: /root/.cache/pip/wheels/a1/04/ee/347bd9f5b821b637c76411d280271a857aece00358896a230f\n","  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-params: filename=py_params-0.10.2-cp36-none-any.whl size=7912 sha256=ca19b49157c41bdd8cd20c728618dd307c7912367758b00ff9329b91d666fcd8\n","  Stored in directory: /root/.cache/pip/wheels/d0/4a/70/ff12450229ff1955abf01f365051d4faae1c20aef53ab4cf09\n","  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19474 sha256=6498da9838a0f5b8afa930c7bd1c19f3395a987f67bf3ae8dc99b44c2ba14627\n","  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n","Successfully built bert-for-tf2 py-params params-flow\n","Installing collected packages: py-params, params-flow, bert-for-tf2\n","Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 5.6MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n","Collecting ktrain\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/3c/8469632f3fa51f244ce35ac184de4c55a260dccfcb7386529faf82ebf60f/ktrain-0.25.4.tar.gz (25.3MB)\n","\u001b[K     |████████████████████████████████| 25.3MB 1.6MB/s \n","\u001b[?25hCollecting scikit-learn==0.23.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n","\u001b[K     |████████████████████████████████| 6.8MB 40.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.2.2)\n","Requirement already satisfied, skipping upgrade: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.1.5)\n","Requirement already satisfied, skipping upgrade: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.0)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.23.0)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.0)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from ktrain) (20.9)\n","Requirement already satisfied, skipping upgrade: ipython in /usr/local/lib/python3.6/dist-packages (from ktrain) (5.5.0)\n","Collecting langdetect\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n","\u001b[K     |████████████████████████████████| 983kB 42.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: jieba in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.42.1)\n","Collecting cchardet\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/e5/a0b9edd8664ea3b0d3270c451ebbf86655ed9fc4c3e4c45b9afae9c2e382/cchardet-2.1.7-cp36-cp36m-manylinux2010_x86_64.whl (263kB)\n","\u001b[K     |████████████████████████████████| 266kB 37.3MB/s \n","\u001b[?25hCollecting syntok\n","  Downloading https://files.pythonhosted.org/packages/8c/76/a49e73a04b3e3a14ce232e8e28a1587f8108baa665644fe8c40e307e792e/syntok-1.3.1.tar.gz\n","Collecting seqeval==0.0.19\n","  Downloading https://files.pythonhosted.org/packages/93/e5/b7705156a77f742cfe4fc6f22d0c71591edb2d243328dff2f8fc0f933ab6/seqeval-0.0.19.tar.gz\n","Collecting transformers<4.0,>=3.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 39.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.1.95)\n","Collecting keras_bert>=0.86.0\n","  Downloading https://files.pythonhosted.org/packages/e2/7f/95fabd29f4502924fa3f09ff6538c5a7d290dfef2c2fe076d3d1a16e08f0/keras-bert-0.86.0.tar.gz\n","Requirement already satisfied, skipping upgrade: networkx>=2.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.5)\n","Collecting whoosh\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n","\u001b[K     |████████████████████████████████| 471kB 39.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.1)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (3.0.4)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (1.24.3)\n","Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (2.6.1)\n","Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (1.0.18)\n","Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.3.3)\n","Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.8.0)\n","Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.8.1)\n","Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.4.2)\n","Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.7.5)\n","Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (53.0.0)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from langdetect->ktrain) (1.15.0)\n","Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from syntok->ktrain) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval==0.0.19->ktrain) (2.4.3)\n","Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (4.41.1)\n","Collecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 38.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (3.12.4)\n","Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (0.8)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 36.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<4.0,>=3.1.0->ktrain) (3.0.12)\n","Collecting keras-transformer>=0.38.0\n","  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n","Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.2.5)\n","Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n","Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.7.0)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain) (2.10.0)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval==0.0.19->ktrain) (3.13)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<4.0,>=3.1.0->ktrain) (7.1.2)\n","Collecting keras-pos-embd>=0.11.0\n","  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n","Collecting keras-multi-head>=0.27.0\n","  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n","Collecting keras-layer-normalization>=0.14.0\n","  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n","Collecting keras-position-wise-feed-forward>=0.6.0\n","  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n","Collecting keras-embed-sim>=0.8.0\n","  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n","Collecting keras-self-attention==0.46.0\n","  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n","Building wheels for collected packages: ktrain, langdetect, syntok, seqeval, keras-bert, sacremoses, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n","  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ktrain: filename=ktrain-0.25.4-cp36-none-any.whl size=25276443 sha256=1ea1ab3bcc9226677045383280114ea93518ee751fff26f2c0cc3b1636bfb582\n","  Stored in directory: /root/.cache/pip/wheels/1b/77/8a/bdceaabc308e7178d575278bf6143b7d1a9b939a1e40c56b88\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993194 sha256=c0e0bfe12f4b59f08a0706df1e5f8a67127c6a4d932ef886ddd3c9733684d23d\n","  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n","  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for syntok: filename=syntok-1.3.1-cp36-none-any.whl size=20918 sha256=7dcf0aef927620d976f206d852810282598b1381aee1db22df6149697b64a6f6\n","  Stored in directory: /root/.cache/pip/wheels/51/c6/a4/be1920586c49469846bcd2888200bdecfe109ec421dab9be2d\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-0.0.19-cp36-none-any.whl size=9919 sha256=f91b7c8e08cef3526b1d736354573a9c411c1c97d5acc179c3b3f73d07860eb5\n","  Stored in directory: /root/.cache/pip/wheels/8d/1f/bf/1198beceed805a2099060975f6281d1b01046dd279e19c97be\n","  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-bert: filename=keras_bert-0.86.0-cp36-none-any.whl size=34145 sha256=890225eae316357eb13dad75dbf12cbd85e789f3e72f5eaa5b1b5bd90d5a0ae3\n","  Stored in directory: /root/.cache/pip/wheels/66/f0/b1/748128b58562fc9e31b907bb5e2ab6a35eb37695e83911236b\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=0ed87c8927a121a7f0671b6f3ef72545f100c04c47b44f74e507a7262dc80e00\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp36-none-any.whl size=12944 sha256=09a11ff8ad510aa1128ee777e1b1f0d025638843c1fb48d9d7dc4c174c6e8d51\n","  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n","  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7553 sha256=15c585650b9fd077ed40cad87faf98db1445a002f660520ffc2da7c63b327762\n","  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n","  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15612 sha256=ef5ceb708e2629d8175793f54237a76df2b580c11f62f202c952e3f5a5acb9f1\n","  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n","  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5267 sha256=0fc4efc0fbd3ecec851277b84aa8d1cbaf0257090d2709ee5cad4977aee2ad1c\n","  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n","  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5625 sha256=f9b4e2304a6bd30d6da6509a0e2b4bf76147631ff1e11abbebc8b6549280e1dd\n","  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n","  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp36-none-any.whl size=4559 sha256=5c060e5d063af54d2c9fd17c6a64be4d9dc6096b30c1455641d5ad5aac3479f2\n","  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n","  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=3b7dde73a8c3470ef7cf742360d46f8e570cc914efe478f7dfd6beb6a6dc614a\n","  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n","Successfully built ktrain langdetect syntok seqeval keras-bert sacremoses keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n","\u001b[31mERROR: transformers 3.5.1 has requirement sentencepiece==0.1.91, but you'll have sentencepiece 0.1.95 which is incompatible.\u001b[0m\n","Installing collected packages: threadpoolctl, scikit-learn, langdetect, cchardet, syntok, seqeval, tokenizers, sacremoses, transformers, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, whoosh, ktrain\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed cchardet-2.1.7 keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0 ktrain-0.25.4 langdetect-1.0.8 sacremoses-0.0.43 scikit-learn-0.23.2 seqeval-0.0.19 syntok-1.3.1 threadpoolctl-2.1.0 tokenizers-0.9.3 transformers-3.5.1 whoosh-2.7.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k9c8qPXfJAmM","executionInfo":{"status":"ok","timestamp":1613626162974,"user_tz":-480,"elapsed":41561,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}}},"source":["try:\r\n","    %tensorflow_version 2.x\r\n","except Exception:\r\n","    pass\r\n","import tensorflow as tf\r\n","\r\n","import tensorflow_hub as hub\r\n","\r\n","from tensorflow.keras import layers\r\n","import bert"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ponsxBJtJAXj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uIcRmTLuH8ih","executionInfo":{"status":"ok","timestamp":1613626167414,"user_tz":-480,"elapsed":42629,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}}},"source":["import keras \n","from keras_multi_head import MultiHead\n","from keras_self_attention import SeqSelfAttention\n","\n","import ktrain\n","from ktrain import text as txt\n","\n","import numpy as np\n","import os\n","import sys\n","\n","import wave\n","import copy\n","import math\n","\n","from keras.models import Sequential, Model\n","from keras.layers.core import Dense, Activation\n","from keras.layers import LSTM, Input, Flatten, Embedding, Convolution1D, Dropout, GRU, Bidirectional\n","from keras.layers.wrappers import TimeDistributed\n","from keras.layers.convolutional import Conv2D\n","from keras.optimizers import SGD, Adam, RMSprop\n","from keras.layers.normalization import BatchNormalization\n","from sklearn.preprocessing import label_binarize\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing import sequence\n","\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a9mADTOAJrxx","executionInfo":{"status":"ok","timestamp":1613626167749,"user_tz":-480,"elapsed":40748,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"7b94f9a0-6826-4a4d-b84e-1b9649c9321b"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/FINAL THESIS PROJECT/codes\r\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/FINAL THESIS PROJECT/codes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-UnOB2k6Jsbj","executionInfo":{"status":"ok","timestamp":1613626169082,"user_tz":-480,"elapsed":40805,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}}},"source":["from features import *\r\n","from helper import *"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"RrRKuYSJH8ir","executionInfo":{"status":"ok","timestamp":1613626169087,"user_tz":-480,"elapsed":38919,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}}},"source":["#code_path = os.path.dirname(os.path.realpath(os.getcwd()))\n","code_path = \"/content/drive/MyDrive/Colab Notebooks/FINAL THESIS PROJECT/data\"\n","emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n","data_path = code_path + \"/\"\n","sessions = ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']\n","framerate = 16000\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"lmcY-wQiH8ir","executionInfo":{"status":"ok","timestamp":1613626202836,"user_tz":-480,"elapsed":71308,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}}},"source":["import pickle\n","with open(data_path +'data_collected.pickle', 'rb') as handle:\n","    data2 = pickle.load(handle)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"yeLpV-XMLw3p","executionInfo":{"status":"ok","timestamp":1613626202842,"user_tz":-480,"elapsed":69617,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}}},"source":["text = []\r\n","\r\n","for ses_mod in data2:\r\n","    text.append(ses_mod['transcription'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"t_Z90v5vH8is","executionInfo":{"status":"ok","timestamp":1613626203171,"user_tz":-480,"elapsed":68611,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}}},"source":["\n","    \n","MAX_SEQUENCE_LENGTH = 500\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(text)\n","\n","token_tr_X = tokenizer.texts_to_sequences(text)\n","x_train_text = []\n","\n","x_train_text = sequence.pad_sequences(token_tr_X, maxlen=MAX_SEQUENCE_LENGTH)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MQg3lInbH8is","executionInfo":{"status":"ok","timestamp":1613626441069,"user_tz":-480,"elapsed":302963,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"e6c589cb-bf21-4e2c-f720-d3a2442f796a"},"source":["import codecs\n","EMBEDDING_DIM = 300\n","\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens' % len(word_index))\n","\n","file_loc = data_path + 'glove.42B.300d/glove.42B.300d.txt'\n","\n","print (file_loc)\n","\n","gembeddings_index = {}\n","with codecs.open(file_loc, encoding='utf-8') as f:\n","    for line in f:\n","        values = line.split(' ')\n","        word = values[0]\n","        gembedding = np.asarray(values[1:], dtype='float32')\n","        gembeddings_index[word] = gembedding\n","#\n","f.close()\n","print('G Word embeddings:', len(gembeddings_index))\n","\n","nb_words = len(word_index) +1\n","g_word_embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    gembedding_vector = gembeddings_index.get(word)\n","    if gembedding_vector is not None:\n","        g_word_embedding_matrix[i] = gembedding_vector\n","        \n","print('G Null word embeddings: %d' % np.sum(np.sum(g_word_embedding_matrix, axis=1) == 0))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Found 2736 unique tokens\n","/content/drive/MyDrive/Colab Notebooks/FINAL THESIS PROJECT/data/glove.42B.300d/glove.42B.300d.txt\n","G Word embeddings: 1917494\n","G Null word embeddings: 90\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wlqRKsBpZqJj","executionInfo":{"status":"ok","timestamp":1613632176946,"user_tz":-480,"elapsed":17015,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}}},"source":["BertTokenizer = bert.bert_tokenization.FullTokenizer\n","bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/1\",\n","                            trainable=True)\n","vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n","to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n","tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"THBjiJlVZ8Gf","executionInfo":{"status":"ok","timestamp":1613632177313,"user_tz":-480,"elapsed":15128,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}}},"source":["tokenizer.tokenize(\"don't be so judgmental\")\n","tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"dont be so judgmental\"))\n","\n","def tokenize_reviews(text):\n","  return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n","\n","token_tr_X1 = []\n","for i in text:\n","  a = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(i))\n","  token_tr_X1.append(a)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AzwpUY1OZ8DG","executionInfo":{"status":"ok","timestamp":1613632265840,"user_tz":-480,"elapsed":1346,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"4ba27492-4014-4cc2-de66-d02b9864574d"},"source":["print(\"Length of token: \", len(token_tr_X1))\n","\n","x_train_text1 = []\n","x_train_text1 = sequence.pad_sequences(token_tr_X1, maxlen=500)\n","\n","print(\"Length of x_train_text1: \", len(x_train_text1))\n","print(x_train_text1)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Length of token:  4936\n","Length of x_train_text1:  4936\n","[[    0     0     0 ... 20676  1143   119]\n"," [    0     0     0 ...     0  2814   119]\n"," [    0     0     0 ...   170  2463   136]\n"," ...\n"," [    0     0     0 ...  1231  1136   119]\n"," [    0     0     0 ...  1174  5656   119]\n"," [    0     0     0 ...   146  1686   119]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WGdN1kmtH8it","executionInfo":{"status":"ok","timestamp":1613626468954,"user_tz":-480,"elapsed":3430,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}}},"source":["def calculate_features(frames, freq, options):\n","    window_sec = 0.2\n","    window_n = int(freq * window_sec)\n","\n","    st_f = stFeatureExtraction(frames, freq, window_n, window_n / 2)\n","\n","    if st_f.shape[1] > 2:\n","        i0 = 1\n","        i1 = st_f.shape[1] - 1\n","        if i1 - i0 < 1:\n","            i1 = i0 + 1\n","        \n","        deriv_st_f = np.zeros((st_f.shape[0], i1 - i0), dtype=float)\n","        for i in range(i0, i1):\n","            i_left = i - 1\n","            i_right = i + 1\n","            deriv_st_f[:st_f.shape[0], i - i0] = st_f[:, i]\n","        return deriv_st_f\n","    elif st_f.shape[1] == 2:\n","        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n","        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n","        return deriv_st_f\n","    else:\n","        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n","        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n","        return deriv_st_f"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"luG_N2SlH8it","executionInfo":{"status":"ok","timestamp":1613626723290,"user_tz":-480,"elapsed":255985,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"ca2a0a20-994b-4aa2-e10b-b42bf6091a4c"},"source":["x_train_speech = []\n","\n","counter = 0\n","for ses_mod in data2:\n","    x_head = ses_mod['signal']\n","    st_features = calculate_features(x_head, framerate, None)\n","    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n","    x_train_speech.append( st_features.T )\n","    counter+=1\n","    if(counter%100==0):\n","        print(counter)\n","    \n","x_train_speech = np.array(x_train_speech)\n","x_train_speech.shape"],"execution_count":16,"outputs":[{"output_type":"stream","text":["100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n","1500\n","1600\n","1700\n","1800\n","1900\n","2000\n","2100\n","2200\n","2300\n","2400\n","2500\n","2600\n","2700\n","2800\n","2900\n","3000\n","3100\n","3200\n","3300\n","3400\n","3500\n","3600\n","3700\n","3800\n","3900\n","4000\n","4100\n","4200\n","4300\n","4400\n","4500\n","4600\n","4700\n","4800\n","4900\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(4936, 100, 34)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jBHKSahYH8it","executionInfo":{"status":"ok","timestamp":1613626747399,"user_tz":-480,"elapsed":276639,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"407122c8-c903-4f3d-da53-c0920196cc3c"},"source":["x_train_mocap = []\n","counter = 0\n","for ses_mod in data2:\n","    x_head = ses_mod['mocap_head']\n","    if(x_head.shape != (200,18)):\n","        x_head = np.zeros((200,18))   \n","    x_head[np.isnan(x_head)]=0\n","    x_hand = ses_mod['mocap_hand']\n","    if(x_hand.shape != (200,6)):\n","        x_hand = np.zeros((200,6))   \n","    x_hand[np.isnan(x_hand)]=0\n","    x_rot = ses_mod['mocap_rot']\n","    if(x_rot.shape != (200,165)):\n","        x_rot = np.zeros((200,165))   \n","    x_rot[np.isnan(x_rot)]=0\n","    x_mocap = np.concatenate((x_head, x_hand), axis=1)\n","    x_mocap = np.concatenate((x_mocap, x_rot), axis=1)\n","    x_train_mocap.append( x_mocap )\n","    \n","x_train_mocap = np.array(x_train_mocap)\n","x_train_mocap = x_train_mocap.reshape(-1,200,189,1)\n","x_train_mocap.shape"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4936, 200, 189, 1)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JcfY0GiFH8iu","executionInfo":{"status":"ok","timestamp":1613626747404,"user_tz":-480,"elapsed":274835,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"38a08065-7828-403b-bfd2-2cfa653ffc97"},"source":["Y=[]\n","for ses_mod in data2:\n","    Y.append(ses_mod['emotion'])\n","    \n","Y = label_binarize(Y,emotions_used)\n","\n","Y.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4936, 4)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pIwnvtgYH8iu","executionInfo":{"status":"ok","timestamp":1613626747409,"user_tz":-480,"elapsed":273724,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"f86f53d1-09de-450f-e2ed-1a8087d94b2a"},"source":["counter = 0\n","for ses_mod in data2:\n","    if (ses_mod['id'][:5]==\"Ses05\"):\n","        break\n","    counter+=1\n","counter"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3838"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1g19KPeIxnKj","executionInfo":{"status":"ok","timestamp":1613632287073,"user_tz":-480,"elapsed":4009,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"bc2165d3-0445-4d06-b08f-21fe459e8237"},"source":["xtrain_tx = x_train_text1[:3838]\r\n","xtest_tx = x_train_text1[3838:]\r\n","ytrain_tx = Y[:3838]\r\n","ytest_tx = Y[3838:]\r\n","\r\n","print(xtrain_tx.shape)\r\n","print(xtest_tx.shape)\r\n","\r\n","print(ytrain_tx.shape)\r\n","print(xtest_tx.shape)\r\n","\r\n","print(xtrain_tx.shape)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["(3838, 500)\n","(1098, 500)\n","(3838, 4)\n","(1098, 500)\n","(3838, 500)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iShKxzbdH8iv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613632212149,"user_tz":-480,"elapsed":1123,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"a215e553-eca3-4357-926a-80e1a315e612"},"source":["xtrain_sp = x_train_speech[:3838]\n","xtest_sp = x_train_speech[3838:]\n","#xtrain_tx = x_train_text[:3838]\n","#xtest_tx = x_train_text[3838:]\n","ytrain_sp = Y[:3838]\n","ytest_sp = Y[3838:]\n","print(xtrain_sp.shape)\n","print(xtest_sp.shape)\n","\n","print(ytrain_sp.shape)\n","print(xtest_sp.shape)\n","\n","print(xtrain_sp.shape)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["(3838, 100, 34)\n","(1098, 100, 34)\n","(3838, 4)\n","(1098, 100, 34)\n","(3838, 100, 34)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t1YI15W2H8iv","executionInfo":{"status":"ok","timestamp":1613632300146,"user_tz":-480,"elapsed":2330,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"f4c07d83-2f75-4f5f-bf69-cf82a51c2759"},"source":["from tensorflow.keras.models import Model, Sequential\n","from keras.layers.core import Dense, Flatten, Activation, Dropout\n","from tensorflow.keras.layers import*\n","from tensorflow.keras.layers import Embedding\n","\n","model_text = Sequential()\n","#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n","embedding_layer = Embedding(nb_words,\n","                    EMBEDDING_DIM,\n","                    weights = [g_word_embedding_matrix],\n","                    input_length = MAX_SEQUENCE_LENGTH,\n","                    trainable = True)\n","sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n","embedded_sequences = embedding_layer(sequence_input)\n","\n","model_text = LSTM(256, return_sequences=True)(embedded_sequences)\n","model_text = LSTM(256, return_sequences=False)(model_text)\n","text_outputs = Dense(256)(model_text)\n","\n","model_text = Model(sequence_input, text_outputs)\n","\n","\n","speech_inputs = Input(shape=(100, 34))\n","model_speech = Flatten()(speech_inputs)\n","model_speech = Dense(1024)(model_speech)\n","model_speech = Activation('relu')(model_speech)\n","model_speech = Dropout(0.2)(model_speech)\n","speech_outputs = Dense(256)(model_speech)\n","\n","model_speech = Model(speech_inputs, speech_outputs)\n","\n","\n","\n","concatenated = concatenate([text_outputs, speech_outputs])\n","\n","model_combined = Activation('relu')(concatenated)\n","out = Dense(256)(model_combined)\n","model_combined = Activation('relu')(out)\n","\n","out = Dense(4, activation='softmax')(model_combined)\n","\n","merged_model = Model([sequence_input, speech_inputs], out)\n","merged_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","\n","\n","#model.compile()\n","model_speech.summary()\n","model_text.summary()\n","merged_model.summary()\n","\n","print(\"Model1 Built\")"],"execution_count":50,"outputs":[{"output_type":"stream","text":["Model: \"model_20\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_13 (InputLayer)        [(None, 100, 34)]         0         \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 3400)              0         \n","_________________________________________________________________\n","dense_30 (Dense)             (None, 1024)              3482624   \n","_________________________________________________________________\n","activation_19 (Activation)   (None, 1024)              0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_31 (Dense)             (None, 256)               262400    \n","=================================================================\n","Total params: 3,745,024\n","Trainable params: 3,745,024\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"model_19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_12 (InputLayer)        [(None, 500)]             0         \n","_________________________________________________________________\n","embedding_10 (Embedding)     (None, 500, 300)          821100    \n","_________________________________________________________________\n","lstm_18 (LSTM)               (None, 500, 256)          570368    \n","_________________________________________________________________\n","lstm_19 (LSTM)               (None, 256)               525312    \n","_________________________________________________________________\n","dense_29 (Dense)             (None, 256)               65792     \n","=================================================================\n","Total params: 1,982,572\n","Trainable params: 1,982,572\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"model_21\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_13 (InputLayer)           [(None, 100, 34)]    0                                            \n","__________________________________________________________________________________________________\n","input_12 (InputLayer)           [(None, 500)]        0                                            \n","__________________________________________________________________________________________________\n","flatten_5 (Flatten)             (None, 3400)         0           input_13[0][0]                   \n","__________________________________________________________________________________________________\n","embedding_10 (Embedding)        (None, 500, 300)     821100      input_12[0][0]                   \n","__________________________________________________________________________________________________\n","dense_30 (Dense)                (None, 1024)         3482624     flatten_5[0][0]                  \n","__________________________________________________________________________________________________\n","lstm_18 (LSTM)                  (None, 500, 256)     570368      embedding_10[0][0]               \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 1024)         0           dense_30[0][0]                   \n","__________________________________________________________________________________________________\n","lstm_19 (LSTM)                  (None, 256)          525312      lstm_18[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 1024)         0           activation_19[0][0]              \n","__________________________________________________________________________________________________\n","dense_29 (Dense)                (None, 256)          65792       lstm_19[0][0]                    \n","__________________________________________________________________________________________________\n","dense_31 (Dense)                (None, 256)          262400      dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 512)          0           dense_29[0][0]                   \n","                                                                 dense_31[0][0]                   \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 512)          0           concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","dense_32 (Dense)                (None, 256)          131328      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 256)          0           dense_32[0][0]                   \n","__________________________________________________________________________________________________\n","dense_33 (Dense)                (None, 4)            1028        activation_21[0][0]              \n","==================================================================================================\n","Total params: 5,859,952\n","Trainable params: 5,859,952\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Model1 Built\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"FPTlRAKUH8iw","colab":{"base_uri":"https://localhost:8080/","height":512},"executionInfo":{"status":"error","timestamp":1613632534761,"user_tz":-480,"elapsed":1165,"user":{"displayName":"Ruddy Rutherford","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpHUEEolzGdLiNefECXA2LUGCwBYeqAPwXLc-g=s64","userId":"08357062561323938612"}},"outputId":"bdbd20a8-49cf-4a60-fd89-0d44588905be"},"source":["hist = merged_model.fit([xtrain_tx,xtrain_sp], ytrain_sp, \n","                 batch_size=64, epochs=5, verbose=1, \n","                 validation_data=([xtest_tx,xtest_sp], ytest_sp))"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-0dd0603177b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = merged_model.fit([xtrain_tx,xtrain_sp], ytrain_sp, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_data=([xtest_tx,xtest_sp], ytest_sp))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[57,486] = 17673 is not in [0, 2737)\n\t [[node model_21/embedding_10/embedding_lookup (defined at <ipython-input-51-0dd0603177b7>:3) ]] [Op:__inference_train_function_63806]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_21/embedding_10/embedding_lookup:\n model_21/embedding_10/embedding_lookup/61572 (defined at /usr/lib/python3.6/contextlib.py:81)\n\nFunction call stack:\ntrain_function\n"]}]},{"cell_type":"code","metadata":{"id":"B-aD63E6H8ix"},"source":["xtrain_mo = x_train_mocap[:3838]\n","xtest_mo = x_train_mocap[3838:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6gPitNJ2H8ix","outputId":"fb1eb1ed-a9e9-45e8-8a1d-6fde3639f93d"},"source":["model_text = Sequential()\n","#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n","model_text.add(Embedding(nb_words,\n","                    EMBEDDING_DIM,\n","                    weights = [g_word_embedding_matrix],\n","                    input_length = MAX_SEQUENCE_LENGTH,\n","                    trainable = True))\n","\n","model_text.add(LSTM(256, return_sequences=True))\n","model_text.add(LSTM(256, return_sequences=False))\n","model_text.add(Dense(256))\n","\n","\n","model_speech = Sequential()\n","model_speech.add(Flatten(input_shape=(100, 34)))\n","model_speech.add(Dense(1024))\n","model_speech.add(Activation('relu'))\n","model_speech.add(Dropout(0.2))\n","model_speech.add(Dense(256))\n","\n","model_mocap = Sequential()\n","model_mocap.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 189, 1)))\n","model_mocap.add(Dropout(0.2))\n","model_mocap.add(Activation('relu'))\n","model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n","model_mocap.add(Dropout(0.2))\n","model_mocap.add(Activation('relu'))\n","model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n","model_mocap.add(Dropout(0.2))\n","model_mocap.add(Activation('relu'))\n","model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n","model_mocap.add(Dropout(0.2))\n","model_mocap.add(Activation('relu'))\n","model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n","model_mocap.add(Dropout(0.2))\n","model_mocap.add(Activation('relu'))\n","model_mocap.add(Flatten())\n","model_mocap.add(Dense(256))\n","\n","model_combined = Sequential()\n","model_combined.add(Merge([model_text, model_speech, model_mocap], mode='concat'))\n","\n","model_combined.add(Activation('relu'))\n","\n","model_combined.add(Dense(256))\n","model_combined.add(Activation('relu'))\n","\n","model_combined.add(Dense(4))\n","model_combined.add(Activation('softmax'))\n","\n","#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n","model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n","\n","## compille it here according to instructions\n","\n","#model.compile()\n","model_speech.summary()\n","model_text.summary()\n","model_mocap.summary()\n","model_combined.summary()\n","\n","print(\"Model1 Built\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, strides=(2, 2), input_shape=(200, 189,..., padding=\"same\")`\n","/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n","/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n","/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n","/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n","/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_4 (Flatten)          (None, 3400)              0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 1024)              3482624   \n","_________________________________________________________________\n","activation_12 (Activation)   (None, 1024)              0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 256)               262400    \n","=================================================================\n","Total params: 3,745,024\n","Trainable params: 3,745,024\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 500, 300)          821100    \n","_________________________________________________________________\n","lstm_3 (LSTM)                (None, 500, 256)          570368    \n","_________________________________________________________________\n","lstm_4 (LSTM)                (None, 256)               525312    \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 256)               65792     \n","=================================================================\n","Total params: 1,982,572\n","Trainable params: 1,982,572\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 100, 95, 32)       320       \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 100, 95, 32)       0         \n","_________________________________________________________________\n","activation_13 (Activation)   (None, 100, 95, 32)       0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 50, 48, 64)        18496     \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 50, 48, 64)        0         \n","_________________________________________________________________\n","activation_14 (Activation)   (None, 50, 48, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 25, 24, 64)        36928     \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 25, 24, 64)        0         \n","_________________________________________________________________\n","activation_15 (Activation)   (None, 25, 24, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 13, 12, 128)       73856     \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 13, 12, 128)       0         \n","_________________________________________________________________\n","activation_16 (Activation)   (None, 13, 12, 128)       0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 7, 6, 128)         147584    \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 7, 6, 128)         0         \n","_________________________________________________________________\n","activation_17 (Activation)   (None, 7, 6, 128)         0         \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 5376)              0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 256)               1376512   \n","=================================================================\n","Total params: 1,653,696\n","Trainable params: 1,653,696\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","merge_3 (Merge)              (None, 768)               0         \n","_________________________________________________________________\n","activation_18 (Activation)   (None, 768)               0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 256)               196864    \n","_________________________________________________________________\n","activation_19 (Activation)   (None, 256)               0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 4)                 1028      \n","_________________________________________________________________\n","activation_20 (Activation)   (None, 4)                 0         \n","=================================================================\n","Total params: 7,579,184\n","Trainable params: 7,579,184\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model1 Built\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"HzOd6aFcH8iz","outputId":"50ef62dc-0ec5-43b4-8ff8-a933dc6528a3"},"source":["hist = model_combined.fit([xtrain_tx,xtrain_sp,xtrain_mo], ytrain_sp, \n","                 batch_size=64, nb_epoch=20, verbose=1, \n","                 validation_data=([xtest_tx,xtest_sp,xtest_mo], ytest_sp))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  warnings.warn('The `nb_epoch` argument in `fit` '\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 3838 samples, validate on 1098 samples\n","Epoch 1/20\n","3838/3838 [==============================] - 109s - loss: 2.3534 - acc: 0.3377 - val_loss: 1.2499 - val_acc: 0.4344\n","Epoch 2/20\n","3838/3838 [==============================] - 101s - loss: 1.0247 - acc: 0.5555 - val_loss: 0.9496 - val_acc: 0.6148\n","Epoch 3/20\n","3838/3838 [==============================] - 101s - loss: 0.7283 - acc: 0.7113 - val_loss: 0.8120 - val_acc: 0.6794\n","Epoch 4/20\n","3838/3838 [==============================] - 100s - loss: 0.5554 - acc: 0.7850 - val_loss: 0.8734 - val_acc: 0.6566\n","Epoch 5/20\n","3838/3838 [==============================] - 104s - loss: 0.4523 - acc: 0.8273 - val_loss: 0.9274 - val_acc: 0.6603\n","Epoch 6/20\n","3838/3838 [==============================] - 108s - loss: 0.3558 - acc: 0.8658 - val_loss: 1.0546 - val_acc: 0.6576\n","Epoch 7/20\n","3838/3838 [==============================] - 109s - loss: 0.3070 - acc: 0.8825 - val_loss: 1.0860 - val_acc: 0.6767\n","Epoch 8/20\n","3838/3838 [==============================] - 106s - loss: 0.2597 - acc: 0.9002 - val_loss: 1.3458 - val_acc: 0.6421\n","Epoch 9/20\n","3838/3838 [==============================] - 103s - loss: 0.2288 - acc: 0.9093 - val_loss: 1.2096 - val_acc: 0.6703\n","Epoch 10/20\n","3838/3838 [==============================] - 100s - loss: 0.2013 - acc: 0.9294 - val_loss: 1.1858 - val_acc: 0.6767\n","Epoch 11/20\n","3838/3838 [==============================] - 99s - loss: 0.1876 - acc: 0.9281 - val_loss: 1.3649 - val_acc: 0.6648\n","Epoch 12/20\n","3838/3838 [==============================] - 97s - loss: 0.1543 - acc: 0.9406 - val_loss: 1.4593 - val_acc: 0.6721\n","Epoch 13/20\n","3838/3838 [==============================] - 98s - loss: 0.1393 - acc: 0.9429 - val_loss: 1.4796 - val_acc: 0.6685\n","Epoch 14/20\n","3838/3838 [==============================] - 97s - loss: 0.1387 - acc: 0.9458 - val_loss: 1.7812 - val_acc: 0.6566\n","Epoch 15/20\n","3838/3838 [==============================] - 99s - loss: 0.1696 - acc: 0.9367 - val_loss: 1.6309 - val_acc: 0.6667\n","Epoch 16/20\n","3838/3838 [==============================] - 99s - loss: 0.1132 - acc: 0.9581 - val_loss: 1.7458 - val_acc: 0.6667\n","Epoch 17/20\n","3838/3838 [==============================] - 100s - loss: 0.1028 - acc: 0.9583 - val_loss: 1.9641 - val_acc: 0.6585\n","Epoch 18/20\n","3838/3838 [==============================] - 102s - loss: 0.0839 - acc: 0.9651 - val_loss: 2.0139 - val_acc: 0.6621\n","Epoch 19/20\n","3838/3838 [==============================] - 102s - loss: 0.0861 - acc: 0.9653 - val_loss: 1.8743 - val_acc: 0.6658\n","Epoch 20/20\n","3838/3838 [==============================] - 102s - loss: 0.0881 - acc: 0.9672 - val_loss: 1.8280 - val_acc: 0.6703\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DVGr76bGH8i0"},"source":["x_train_mocap2 = x_train_mocap.reshape(-1,200,189)\n","xtrain_mo = x_train_mocap2[:3838]\n","xtest_mo = x_train_mocap2[3838:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swJghGNfH8i0","outputId":"53b8f4d4-e011-4a01-8365-0196d2a68f45"},"source":["model_text = Sequential()\n","#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n","model_text.add(Embedding(nb_words,\n","                    EMBEDDING_DIM,\n","                    weights = [g_word_embedding_matrix],\n","                    input_length = MAX_SEQUENCE_LENGTH,\n","                    trainable = True))\n","\n","model_text.add(LSTM(256, return_sequences=True))\n","model_text.add(LSTM(256, return_sequences=False))\n","model_text.add(Dense(256))\n","\n","\n","model_speech = Sequential()\n","model_speech.add(Flatten(input_shape=(100, 34)))\n","model_speech.add(Dense(1024))\n","model_speech.add(Activation('relu'))\n","model_speech.add(Dropout(0.2))\n","model_speech.add(Dense(256))\n","\n","model_mocap = Sequential()\n","model_mocap.add(LSTM(256, return_sequences=True, input_shape=(200, 189)))\n","model_mocap.add(LSTM(256, return_sequences=False))\n","model_mocap.add(Dense(256))\n","\n","model_combined = Sequential()\n","model_combined.add(Merge([model_text, model_speech, model_mocap], mode='concat'))\n","\n","model_combined.add(Activation('relu'))\n","\n","model_combined.add(Dense(256))\n","model_combined.add(Activation('relu'))\n","\n","model_combined.add(Dense(4))\n","model_combined.add(Activation('softmax'))\n","\n","#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n","model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n","\n","## compille it here according to instructions\n","\n","#model.compile()\n","model_speech.summary()\n","model_text.summary()\n","model_mocap.summary()\n","model_combined.summary()\n","\n","print(\"Model1 Built\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_6 (Flatten)          (None, 3400)              0         \n","_________________________________________________________________\n","dense_21 (Dense)             (None, 1024)              3482624   \n","_________________________________________________________________\n","activation_21 (Activation)   (None, 1024)              0         \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 1024)              0         \n","_________________________________________________________________\n","dense_22 (Dense)             (None, 256)               262400    \n","=================================================================\n","Total params: 3,745,024\n","Trainable params: 3,745,024\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 500, 300)          821100    \n","_________________________________________________________________\n","lstm_5 (LSTM)                (None, 500, 256)          570368    \n","_________________________________________________________________\n","lstm_6 (LSTM)                (None, 256)               525312    \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 256)               65792     \n","=================================================================\n","Total params: 1,982,572\n","Trainable params: 1,982,572\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_7 (LSTM)                (None, 200, 256)          456704    \n","_________________________________________________________________\n","lstm_8 (LSTM)                (None, 256)               525312    \n","_________________________________________________________________\n","dense_23 (Dense)             (None, 256)               65792     \n","=================================================================\n","Total params: 1,047,808\n","Trainable params: 1,047,808\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","merge_4 (Merge)              (None, 768)               0         \n","_________________________________________________________________\n","activation_22 (Activation)   (None, 768)               0         \n","_________________________________________________________________\n","dense_24 (Dense)             (None, 256)               196864    \n","_________________________________________________________________\n","activation_23 (Activation)   (None, 256)               0         \n","_________________________________________________________________\n","dense_25 (Dense)             (None, 4)                 1028      \n","_________________________________________________________________\n","activation_24 (Activation)   (None, 4)                 0         \n","=================================================================\n","Total params: 6,973,296\n","Trainable params: 6,973,296\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model1 Built\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"NdA38IEKH8i0","outputId":"f16eac7c-3db1-4c56-87f4-6ace4ac58800"},"source":["hist = model_combined.fit([xtrain_tx,xtrain_sp,xtrain_mo], ytrain_sp, \n","                 batch_size=64, nb_epoch=20, verbose=1, \n","                 validation_data=([xtest_tx,xtest_sp,xtest_mo], ytest_sp))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  warnings.warn('The `nb_epoch` argument in `fit` '\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 3838 samples, validate on 1098 samples\n","Epoch 1/20\n","3838/3838 [==============================] - 135s - loss: 1.5098 - acc: 0.3794 - val_loss: 1.2127 - val_acc: 0.4572\n","Epoch 2/20\n","3838/3838 [==============================] - 132s - loss: 1.0074 - acc: 0.5732 - val_loss: 0.9689 - val_acc: 0.5984\n","Epoch 3/20\n","3838/3838 [==============================] - 131s - loss: 0.7328 - acc: 0.7084 - val_loss: 0.9150 - val_acc: 0.6330\n","Epoch 4/20\n","3838/3838 [==============================] - 133s - loss: 0.5839 - acc: 0.7723 - val_loss: 0.8540 - val_acc: 0.6730\n","Epoch 5/20\n","3838/3838 [==============================] - 132s - loss: 0.4515 - acc: 0.8286 - val_loss: 0.9827 - val_acc: 0.6667\n","Epoch 6/20\n","3838/3838 [==============================] - 133s - loss: 0.3672 - acc: 0.8559 - val_loss: 0.9922 - val_acc: 0.6730\n","Epoch 7/20\n","3838/3838 [==============================] - 132s - loss: 0.3202 - acc: 0.8757 - val_loss: 1.0905 - val_acc: 0.6730\n","Epoch 8/20\n","3838/3838 [==============================] - 133s - loss: 0.2622 - acc: 0.9010 - val_loss: 1.0578 - val_acc: 0.6858\n","Epoch 9/20\n","3838/3838 [==============================] - 133s - loss: 0.2252 - acc: 0.9169 - val_loss: 1.2785 - val_acc: 0.6785\n","Epoch 10/20\n","3838/3838 [==============================] - 133s - loss: 0.1989 - acc: 0.9257 - val_loss: 1.2943 - val_acc: 0.6557\n","Epoch 11/20\n","3838/3838 [==============================] - 129s - loss: 0.2019 - acc: 0.9247 - val_loss: 1.3847 - val_acc: 0.6658\n","Epoch 12/20\n","3838/3838 [==============================] - 130s - loss: 0.1568 - acc: 0.9440 - val_loss: 1.4129 - val_acc: 0.6603\n","Epoch 13/20\n","3838/3838 [==============================] - 132s - loss: 0.1599 - acc: 0.9409 - val_loss: 1.5436 - val_acc: 0.6466\n","Epoch 14/20\n","3838/3838 [==============================] - 133s - loss: 0.1425 - acc: 0.9461 - val_loss: 1.7256 - val_acc: 0.6521\n","Epoch 15/20\n","3838/3838 [==============================] - 133s - loss: 0.1347 - acc: 0.9492 - val_loss: 1.7604 - val_acc: 0.6612\n","Epoch 16/20\n","3838/3838 [==============================] - 133s - loss: 0.1132 - acc: 0.9581 - val_loss: 1.7174 - val_acc: 0.6603\n","Epoch 17/20\n","3838/3838 [==============================] - 132s - loss: 0.1005 - acc: 0.9643 - val_loss: 2.2605 - val_acc: 0.6393\n","Epoch 18/20\n"," 960/3838 [======>.......................] - ETA: 93s - loss: 0.0934 - acc: 0.9656"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-246df15326f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model_combined.fit([xtrain_tx,xtrain_sp,xtrain_mo], ytrain_sp, \n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  validation_data=([xtest_tx,xtest_sp,xtest_mo], ytest_sp))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n","\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"tBcppK0wH8i1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PYl4NcMjH8i1"},"source":["import tensorflow as tf\n","from keras import backend as K\n","from keras import regularizers, constraints, initializers, activations\n","from keras.layers.recurrent import Recurrent, _time_distributed_dense\n","from keras.engine import InputSpec\n","\n","tfPrint = lambda d, T: tf.Print(input_=T, data=[T, tf.shape(T)], message=d)\n","\n","class AttentionDecoder(Recurrent):\n","\n","    def __init__(self, units, output_dim,\n","                 activation='tanh',\n","                 return_probabilities=False,\n","                 name='AttentionDecoder',\n","                 kernel_initializer='glorot_uniform',\n","                 recurrent_initializer='orthogonal',\n","                 bias_initializer='zeros',\n","                 kernel_regularizer=None,\n","                 bias_regularizer=None,\n","                 activity_regularizer=None,\n","                 kernel_constraint=None,\n","                 bias_constraint=None,\n","                 **kwargs):\n","        \"\"\"\n","        Implements an AttentionDecoder that takes in a sequence encoded by an\n","        encoder and outputs the decoded states\n","        :param units: dimension of the hidden state and the attention matrices\n","        :param output_dim: the number of labels in the output space\n","\n","        references:\n","            Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio.\n","            \"Neural machine translation by jointly learning to align and translate.\"\n","            arXiv preprint arXiv:1409.0473 (2014).\n","        \"\"\"\n","        self.units = units\n","        self.output_dim = output_dim\n","        self.return_probabilities = return_probabilities\n","        self.activation = activations.get(activation)\n","        self.kernel_initializer = initializers.get(kernel_initializer)\n","        self.recurrent_initializer = initializers.get(recurrent_initializer)\n","        self.bias_initializer = initializers.get(bias_initializer)\n","\n","        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n","        self.recurrent_regularizer = regularizers.get(kernel_regularizer)\n","        self.bias_regularizer = regularizers.get(bias_regularizer)\n","        self.activity_regularizer = regularizers.get(activity_regularizer)\n","\n","        self.kernel_constraint = constraints.get(kernel_constraint)\n","        self.recurrent_constraint = constraints.get(kernel_constraint)\n","        self.bias_constraint = constraints.get(bias_constraint)\n","\n","        super(AttentionDecoder, self).__init__(**kwargs)\n","        self.name = name\n","        self.return_sequences = True  # must return sequences\n","\n","    def build(self, input_shape):\n","        \"\"\"\n","          See Appendix 2 of Bahdanau 2014, arXiv:1409.0473\n","          for model details that correspond to the matrices here.\n","        \"\"\"\n","\n","        self.batch_size, self.timesteps, self.input_dim = input_shape\n","\n","        if self.stateful:\n","            super(AttentionDecoder, self).reset_states()\n","\n","        self.states = [None, None]  # y, s\n","\n","        \"\"\"\n","            Matrices for creating the context vector\n","        \"\"\"\n","\n","        self.V_a = self.add_weight(shape=(self.units,),\n","                                   name='V_a',\n","                                   initializer=self.kernel_initializer,\n","                                   regularizer=self.kernel_regularizer,\n","                                   constraint=self.kernel_constraint)\n","        self.W_a = self.add_weight(shape=(self.units, self.units),\n","                                   name='W_a',\n","                                   initializer=self.kernel_initializer,\n","                                   regularizer=self.kernel_regularizer,\n","                                   constraint=self.kernel_constraint)\n","        self.U_a = self.add_weight(shape=(self.input_dim, self.units),\n","                                   name='U_a',\n","                                   initializer=self.kernel_initializer,\n","                                   regularizer=self.kernel_regularizer,\n","                                   constraint=self.kernel_constraint)\n","        self.b_a = self.add_weight(shape=(self.units,),\n","                                   name='b_a',\n","                                   initializer=self.bias_initializer,\n","                                   regularizer=self.bias_regularizer,\n","                                   constraint=self.bias_constraint)\n","        \"\"\"\n","            Matrices for the r (reset) gate\n","        \"\"\"\n","        self.C_r = self.add_weight(shape=(self.input_dim, self.units),\n","                                   name='C_r',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.U_r = self.add_weight(shape=(self.units, self.units),\n","                                   name='U_r',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.W_r = self.add_weight(shape=(self.output_dim, self.units),\n","                                   name='W_r',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.b_r = self.add_weight(shape=(self.units, ),\n","                                   name='b_r',\n","                                   initializer=self.bias_initializer,\n","                                   regularizer=self.bias_regularizer,\n","                                   constraint=self.bias_constraint)\n","\n","        \"\"\"\n","            Matrices for the z (update) gate\n","        \"\"\"\n","        self.C_z = self.add_weight(shape=(self.input_dim, self.units),\n","                                   name='C_z',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.U_z = self.add_weight(shape=(self.units, self.units),\n","                                   name='U_z',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.W_z = self.add_weight(shape=(self.output_dim, self.units),\n","                                   name='W_z',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.b_z = self.add_weight(shape=(self.units, ),\n","                                   name='b_z',\n","                                   initializer=self.bias_initializer,\n","                                   regularizer=self.bias_regularizer,\n","                                   constraint=self.bias_constraint)\n","        \"\"\"\n","            Matrices for the proposal\n","        \"\"\"\n","        self.C_p = self.add_weight(shape=(self.input_dim, self.units),\n","                                   name='C_p',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.U_p = self.add_weight(shape=(self.units, self.units),\n","                                   name='U_p',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.W_p = self.add_weight(shape=(self.output_dim, self.units),\n","                                   name='W_p',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.b_p = self.add_weight(shape=(self.units, ),\n","                                   name='b_p',\n","                                   initializer=self.bias_initializer,\n","                                   regularizer=self.bias_regularizer,\n","                                   constraint=self.bias_constraint)\n","        \"\"\"\n","            Matrices for making the final prediction vector\n","        \"\"\"\n","        self.C_o = self.add_weight(shape=(self.input_dim, self.output_dim),\n","                                   name='C_o',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.U_o = self.add_weight(shape=(self.units, self.output_dim),\n","                                   name='U_o',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.W_o = self.add_weight(shape=(self.output_dim, self.output_dim),\n","                                   name='W_o',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","        self.b_o = self.add_weight(shape=(self.output_dim, ),\n","                                   name='b_o',\n","                                   initializer=self.bias_initializer,\n","                                   regularizer=self.bias_regularizer,\n","                                   constraint=self.bias_constraint)\n","\n","        # For creating the initial state:\n","        self.W_s = self.add_weight(shape=(self.input_dim, self.units),\n","                                   name='W_s',\n","                                   initializer=self.recurrent_initializer,\n","                                   regularizer=self.recurrent_regularizer,\n","                                   constraint=self.recurrent_constraint)\n","\n","        self.input_spec = [\n","            InputSpec(shape=(self.batch_size, self.timesteps, self.input_dim))]\n","        self.built = True\n","\n","    def call(self, x):\n","        # store the whole sequence so we can \"attend\" to it at each timestep\n","        self.x_seq = x\n","\n","        # apply the a dense layer over the time dimension of the sequence\n","        # do it here because it doesn't depend on any previous steps\n","        # thefore we can save computation time:\n","        self._uxpb = _time_distributed_dense(self.x_seq, self.U_a, b=self.b_a,\n","                                             input_dim=self.input_dim,\n","                                             timesteps=self.timesteps,\n","                                             output_dim=self.units)\n","\n","        return super(AttentionDecoder, self).call(x)\n","\n","    def get_initial_state(self, inputs):\n","        # apply the matrix on the first time step to get the initial s0.\n","        s0 = activations.tanh(K.dot(inputs[:, 0], self.W_s))\n","\n","        # from keras.layers.recurrent to initialize a vector of (batchsize,\n","        # output_dim)\n","        y0 = K.zeros_like(inputs)  # (samples, timesteps, input_dims)\n","        y0 = K.sum(y0, axis=(1, 2))  # (samples, )\n","        y0 = K.expand_dims(y0)  # (samples, 1)\n","        y0 = K.tile(y0, [1, self.output_dim])\n","\n","        return [y0, s0]\n","\n","    def step(self, x, states):\n","\n","        ytm, stm = states\n","\n","        # repeat the hidden state to the length of the sequence\n","        _stm = K.repeat(stm, self.timesteps)\n","\n","        # now multiplty the weight matrix with the repeated hidden state\n","        _Wxstm = K.dot(_stm, self.W_a)\n","\n","        # calculate the attention probabilities\n","        # this relates how much other timesteps contributed to this one.\n","        et = K.dot(activations.tanh(_Wxstm + self._uxpb),\n","                   K.expand_dims(self.V_a))\n","        at = K.exp(et)\n","        at_sum = K.sum(at, axis=1)\n","        at_sum_repeated = K.repeat(at_sum, self.timesteps)\n","        at /= at_sum_repeated  # vector of size (batchsize, timesteps, 1)\n","\n","        # calculate the context vector\n","        context = K.squeeze(K.batch_dot(at, self.x_seq, axes=1), axis=1)\n","        # ~~~> calculate new hidden state\n","        # first calculate the \"r\" gate:\n","\n","        rt = activations.sigmoid(\n","            K.dot(ytm, self.W_r)\n","            + K.dot(stm, self.U_r)\n","            + K.dot(context, self.C_r)\n","            + self.b_r)\n","\n","        # now calculate the \"z\" gate\n","        zt = activations.sigmoid(\n","            K.dot(ytm, self.W_z)\n","            + K.dot(stm, self.U_z)\n","            + K.dot(context, self.C_z)\n","            + self.b_z)\n","\n","        # calculate the proposal hidden state:\n","        s_tp = activations.tanh(\n","            K.dot(ytm, self.W_p)\n","            + K.dot((rt * stm), self.U_p)\n","            + K.dot(context, self.C_p)\n","            + self.b_p)\n","\n","        # new hidden state:\n","        st = (1-zt)*stm + zt * s_tp\n","\n","        yt = activations.softmax(\n","            K.dot(ytm, self.W_o)\n","            + K.dot(stm, self.U_o)\n","            + K.dot(context, self.C_o)\n","            + self.b_o)\n","\n","        if self.return_probabilities:\n","            return at, [yt, st]\n","        else:\n","            return yt, [yt, st]\n","\n","    def compute_output_shape(self, input_shape):\n","        \"\"\"\n","            For Keras internal compatability checking\n","        \"\"\"\n","        if self.return_probabilities:\n","            return (None, self.timesteps, self.timesteps)\n","        else:\n","            return (None, self.timesteps, self.output_dim)\n","\n","    def get_config(self):\n","        \"\"\"\n","            For rebuilding models on load time.\n","        \"\"\"\n","        config = {\n","            'output_dim': self.output_dim,\n","            'units': self.units,\n","            'return_probabilities': self.return_probabilities\n","        }\n","        base_config = super(AttentionDecoder, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBYzuMj5H8i6","outputId":"063abdfd-cfd9-44c3-9499-77c2939d1b9b"},"source":["model_text = Sequential()\n","#model.add(Embedding(2737, 128, input_length=MAX_SEQUENCE_LENGTH))\n","model_text.add(Embedding(nb_words,\n","                    EMBEDDING_DIM,\n","                    weights = [g_word_embedding_matrix],\n","                    input_length = MAX_SEQUENCE_LENGTH,\n","                    trainable = True))\n","\n","model_text.add(LSTM(256, return_sequences=True, recurrent_dropout = 0.2))\n","model_text.add(Dropout(0.2))\n","model_text.add(LSTM(256, return_sequences=False, recurrent_dropout = 0.2))\n","model_text.add(Dropout(0.2))\n","model_text.add(Dense(256))\n","\n","\n","model_speech = Sequential()\n","model_speech.add(LSTM(128, return_sequences=True, input_shape=(100, 34), recurrent_dropout = 0.2))\n","model_speech.add(Dropout(0.2))\n","model_speech.add(AttentionDecoder(128,128))\n","model_speech.add(Dropout(0.2))\n","model_speech.add(Flatten())\n","model_speech.add(Dense(256))\n","\n","model_mocap = Sequential()\n","model_mocap.add(Conv2D(32, 3, strides=(2, 2), border_mode='same', input_shape=(200, 189, 1)))\n","model_mocap.add(Dropout(0.2))\n","model_mocap.add(Activation('relu'))\n","model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n","model_mocap.add(Dropout(0.2))\n","model_mocap.add(Activation('relu'))\n","model_mocap.add(Conv2D(64, 3, strides=(2, 2), border_mode='same'))\n","model_mocap.add(Dropout(0.2))\n","model_mocap.add(Activation('relu'))\n","model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n","model_mocap.add(Dropout(0.2))\n","model_mocap.add(Activation('relu'))\n","model_mocap.add(Conv2D(128, 3, strides=(2, 2), border_mode='same'))\n","model_mocap.add(Dropout(0.2))\n","model_mocap.add(Activation('relu'))\n","model_mocap.add(Flatten())\n","model_mocap.add(Dense(256))\n","\n","model_combined = Sequential()\n","model_combined.add(Merge([model_text, model_speech, model_mocap], mode='concat'))\n","\n","model_combined.add(Activation('relu'))\n","\n","model_combined.add(Dense(256))\n","model_combined.add(Activation('relu'))\n","\n","model_combined.add(Dense(4))\n","model_combined.add(Activation('softmax'))\n","\n","#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n","model_combined.compile(loss='categorical_crossentropy',optimizer='Adam' ,metrics=['acc'])\n","\n","## compille it here according to instructions\n","\n","#model.compile()\n","model_speech.summary()\n","model_text.summary()\n","model_mocap.summary()\n","model_combined.summary()\n","\n","print(\"Model1 Built\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_17 (LSTM)               (None, 100, 128)          83456     \n","_________________________________________________________________\n","dropout_21 (Dropout)         (None, 100, 128)          0         \n","_________________________________________________________________\n","AttentionDecoder (AttentionD (None, 100, 128)          246528    \n","_________________________________________________________________\n","dropout_22 (Dropout)         (None, 100, 128)          0         \n","_________________________________________________________________\n","flatten_7 (Flatten)          (None, 12800)             0         \n","_________________________________________________________________\n","dense_29 (Dense)             (None, 256)               3277056   \n","=================================================================\n","Total params: 3,607,040\n","Trainable params: 3,607,040\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_7 (Embedding)      (None, 500, 300)          821100    \n","_________________________________________________________________\n","lstm_15 (LSTM)               (None, 500, 256)          570368    \n","_________________________________________________________________\n","dropout_19 (Dropout)         (None, 500, 256)          0         \n","_________________________________________________________________\n","lstm_16 (LSTM)               (None, 256)               525312    \n","_________________________________________________________________\n","dropout_20 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_28 (Dense)             (None, 256)               65792     \n","=================================================================\n","Total params: 1,982,572\n","Trainable params: 1,982,572\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_6 (Conv2D)            (None, 100, 95, 32)       320       \n","_________________________________________________________________\n","dropout_23 (Dropout)         (None, 100, 95, 32)       0         \n","_________________________________________________________________\n","activation_25 (Activation)   (None, 100, 95, 32)       0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 50, 48, 64)        18496     \n","_________________________________________________________________\n","dropout_24 (Dropout)         (None, 50, 48, 64)        0         \n","_________________________________________________________________\n","activation_26 (Activation)   (None, 50, 48, 64)        0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 25, 24, 64)        36928     \n","_________________________________________________________________\n","dropout_25 (Dropout)         (None, 25, 24, 64)        0         \n","_________________________________________________________________\n","activation_27 (Activation)   (None, 25, 24, 64)        0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 13, 12, 128)       73856     \n","_________________________________________________________________\n","dropout_26 (Dropout)         (None, 13, 12, 128)       0         \n","_________________________________________________________________\n","activation_28 (Activation)   (None, 13, 12, 128)       0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 7, 6, 128)         147584    \n","_________________________________________________________________\n","dropout_27 (Dropout)         (None, 7, 6, 128)         0         \n","_________________________________________________________________\n","activation_29 (Activation)   (None, 7, 6, 128)         0         \n","_________________________________________________________________\n","flatten_8 (Flatten)          (None, 5376)              0         \n","_________________________________________________________________\n","dense_30 (Dense)             (None, 256)               1376512   \n","=================================================================\n","Total params: 1,653,696\n","Trainable params: 1,653,696\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","merge_5 (Merge)              (None, 768)               0         \n","_________________________________________________________________\n","activation_30 (Activation)   (None, 768)               0         \n","_________________________________________________________________\n","dense_31 (Dense)             (None, 256)               196864    \n","_________________________________________________________________\n","activation_31 (Activation)   (None, 256)               0         \n","_________________________________________________________________\n","dense_32 (Dense)             (None, 4)                 1028      \n","_________________________________________________________________\n","activation_32 (Activation)   (None, 4)                 0         \n","=================================================================\n","Total params: 7,441,200\n","Trainable params: 7,441,200\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model1 Built\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, 3, strides=(2, 2), input_shape=(200, 189,..., padding=\"same\")`\n","/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n","/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, 3, strides=(2, 2), padding=\"same\")`\n","/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n","/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, 3, strides=(2, 2), padding=\"same\")`\n","/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:44: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"nD6hcEcdH8i7"},"source":["xtrain_mo = x_train_mocap[:3838]\n","xtest_mo = x_train_mocap[3838:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"lXJRrnX6H8i7","outputId":"0c6cef33-c057-40a3-cf6b-5accfcafcc05"},"source":["hist = model_combined.fit([xtrain_tx,xtrain_sp,xtrain_mo], ytrain_sp, \n","                 batch_size=64, nb_epoch=20, verbose=1, \n","                 validation_data=([xtest_tx,xtest_sp,xtest_mo], ytest_sp))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  warnings.warn('The `nb_epoch` argument in `fit` '\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 3838 samples, validate on 1098 samples\n","Epoch 1/20\n","3838/3838 [==============================] - 134s - loss: 1.3780 - acc: 0.3619 - val_loss: 1.1874 - val_acc: 0.4818\n","Epoch 2/20\n","3838/3838 [==============================] - 134s - loss: 1.0887 - acc: 0.5328 - val_loss: 1.0259 - val_acc: 0.5765\n","Epoch 3/20\n","3838/3838 [==============================] - 134s - loss: 0.8234 - acc: 0.6701 - val_loss: 0.9108 - val_acc: 0.6248\n","Epoch 4/20\n","3838/3838 [==============================] - 132s - loss: 0.6451 - acc: 0.7603 - val_loss: 1.0393 - val_acc: 0.6211\n","Epoch 5/20\n","3838/3838 [==============================] - 133s - loss: 0.5396 - acc: 0.7934 - val_loss: 0.9689 - val_acc: 0.6384\n","Epoch 6/20\n","3838/3838 [==============================] - 132s - loss: 0.4569 - acc: 0.8236 - val_loss: 0.9315 - val_acc: 0.6840\n","Epoch 7/20\n","3838/3838 [==============================] - 131s - loss: 0.3741 - acc: 0.8551 - val_loss: 1.1224 - val_acc: 0.6321\n","Epoch 8/20\n","3838/3838 [==============================] - 133s - loss: 0.3268 - acc: 0.8768 - val_loss: 1.0418 - val_acc: 0.6639\n","Epoch 9/20\n","3838/3838 [==============================] - 132s - loss: 0.2834 - acc: 0.8882 - val_loss: 1.2462 - val_acc: 0.6475\n","Epoch 10/20\n","3838/3838 [==============================] - 132s - loss: 0.2565 - acc: 0.8973 - val_loss: 1.3563 - val_acc: 0.6585\n","Epoch 11/20\n","3838/3838 [==============================] - 131s - loss: 0.2416 - acc: 0.9049 - val_loss: 1.1327 - val_acc: 0.6685\n","Epoch 12/20\n","3838/3838 [==============================] - 133s - loss: 0.1945 - acc: 0.9252 - val_loss: 1.2870 - val_acc: 0.6749\n","Epoch 13/20\n","3838/3838 [==============================] - 133s - loss: 0.1946 - acc: 0.9203 - val_loss: 1.3988 - val_acc: 0.6730\n","Epoch 14/20\n","3838/3838 [==============================] - 132s - loss: 0.1832 - acc: 0.9270 - val_loss: 1.4882 - val_acc: 0.6776\n","Epoch 15/20\n","3838/3838 [==============================] - 132s - loss: 0.1646 - acc: 0.9338 - val_loss: 1.5878 - val_acc: 0.6375\n","Epoch 16/20\n","3838/3838 [==============================] - 134s - loss: 0.1568 - acc: 0.9377 - val_loss: 1.5469 - val_acc: 0.6703\n","Epoch 17/20\n","3838/3838 [==============================] - 132s - loss: 0.7564 - acc: 0.7129 - val_loss: 0.8586 - val_acc: 0.6785\n","Epoch 18/20\n","3838/3838 [==============================] - 131s - loss: 0.3478 - acc: 0.8627 - val_loss: 0.9505 - val_acc: 0.7104\n","Epoch 19/20\n","3838/3838 [==============================] - 133s - loss: 0.2167 - acc: 0.9171 - val_loss: 1.0780 - val_acc: 0.6922\n","Epoch 20/20\n","3838/3838 [==============================] - 130s - loss: 0.3928 - acc: 0.8471 - val_loss: 1.0349 - val_acc: 0.6685\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"npJ5QGWEH8i7","outputId":"ff6e0279-b9bc-4d87-9f89-6b8e3fd013ea"},"source":["hist = model_combined.fit([xtrain_tx,xtrain_sp,xtrain_mo], ytrain_sp, \n","                 batch_size=64, nb_epoch=25, verbose=1, \n","                 validation_data=([xtest_tx,xtest_sp,xtest_mo], ytest_sp))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train on 3838 samples, validate on 1098 samples\n","Epoch 1/10\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.5/dist-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  warnings.warn('The `nb_epoch` argument in `fit` '\n"],"name":"stderr"},{"output_type":"stream","text":["3838/3838 [==============================] - 133s - loss: 0.3763 - acc: 0.8525 - val_loss: 0.9981 - val_acc: 0.6658\n","Epoch 2/10\n","3838/3838 [==============================] - 135s - loss: 0.3503 - acc: 0.8606 - val_loss: 1.4561 - val_acc: 0.6184\n","Epoch 3/10\n","3838/3838 [==============================] - 134s - loss: 0.3502 - acc: 0.8637 - val_loss: 1.1833 - val_acc: 0.6667\n","Epoch 4/10\n","3838/3838 [==============================] - 134s - loss: 0.3165 - acc: 0.8760 - val_loss: 1.0661 - val_acc: 0.6740\n","Epoch 5/10\n","3838/3838 [==============================] - 134s - loss: 0.3003 - acc: 0.8796 - val_loss: 1.1590 - val_acc: 0.6694\n","Epoch 6/10\n","3838/3838 [==============================] - 134s - loss: 0.2903 - acc: 0.8867 - val_loss: 1.3824 - val_acc: 0.6175\n","Epoch 7/10\n","3838/3838 [==============================] - 133s - loss: 0.2639 - acc: 0.8960 - val_loss: 1.2120 - val_acc: 0.6694\n","Epoch 8/10\n","3838/3838 [==============================] - 134s - loss: 0.2600 - acc: 0.8999 - val_loss: 1.1252 - val_acc: 0.6821\n","Epoch 9/10\n","3838/3838 [==============================] - 134s - loss: 0.2405 - acc: 0.9044 - val_loss: 1.2397 - val_acc: 0.6639\n","Epoch 10/10\n","3838/3838 [==============================] - 135s - loss: 0.2285 - acc: 0.9114 - val_loss: 1.3532 - val_acc: 0.6457\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oswNX83xH8i7"},"source":[""],"execution_count":null,"outputs":[]}]}